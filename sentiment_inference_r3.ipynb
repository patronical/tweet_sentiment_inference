{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Sentiment Inference Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-15 15:58:36</td>\n",
       "      <td>ConsenSys is reportedly trying to attract outs...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-15 15:11:55</td>\n",
       "      <td>Don't miss the most memorable quotes from last...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-15 15:09:47</td>\n",
       "      <td>Portland State University researchers have pre...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-15 14:01:08</td>\n",
       "      <td>Reuters: France to ask other EU states to adop...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-15 13:11:07</td>\n",
       "      <td>Ethereum engineer Lukas Hohl has joined Swissc...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              tweet  \\\n",
       "0  2019-04-15 15:58:36  ConsenSys is reportedly trying to attract outs...   \n",
       "1  2019-04-15 15:11:55  Don't miss the most memorable quotes from last...   \n",
       "2  2019-04-15 15:09:47  Portland State University researchers have pre...   \n",
       "3  2019-04-15 14:01:08  Reuters: France to ask other EU states to adop...   \n",
       "4  2019-04-15 13:11:07  Ethereum engineer Lukas Hohl has joined Swissc...   \n",
       "\n",
       "              id lang  \n",
       "0  Cointelegraph   en  \n",
       "1  Cointelegraph   en  \n",
       "2  Cointelegraph   en  \n",
       "3  Cointelegraph   en  \n",
       "4  Cointelegraph   en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load network tweets\n",
    "df_net = pd.read_csv(\"df_tweet_r2.csv\")\n",
    "df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4983</td>\n",
       "      <td>4960</td>\n",
       "      <td>4983</td>\n",
       "      <td>4921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4910</td>\n",
       "      <td>4918</td>\n",
       "      <td>129</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2019-04-16 13:24:07</td>\n",
       "      <td>A rich life: 1. You and your loved ones are he...</td>\n",
       "      <td>evankirstel</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>897</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  \\\n",
       "count                  4983   \n",
       "unique                 4910   \n",
       "top     2019-04-16 13:24:07   \n",
       "freq                      3   \n",
       "\n",
       "                                                    tweet           id  lang  \n",
       "count                                                4960         4983  4921  \n",
       "unique                                               4918          129    32  \n",
       "top     A rich life: 1. You and your loved ones are he...  evankirstel    en  \n",
       "freq                                                    3          897  4573  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_net.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_eng = df_net[df_net['lang']=='en'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Vocab from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_r1.pickle', 'rb') as handle:\n",
    "    vocab = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def preprocess(message):\n",
    "    \"\"\"\n",
    "    This function takes a string as input, then performs these operations: \n",
    "        - lowercase\n",
    "        - remove URLs\n",
    "        - remove ticker symbols \n",
    "        - removes punctuation\n",
    "        - tokenize by splitting the string on whitespace \n",
    "        - removes any single character tokens\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        message : The text message to be preprocessed.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        tokens: The preprocessed text into tokens.\n",
    "    \"\"\" \n",
    "    #TODO: Implement \n",
    "\n",
    "    # Lowercase the twit message\n",
    "    text = message.lower()\n",
    "    \n",
    "    # Replace URLs with a space in the message\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    \n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    text = re.sub(r\"\\$\\S+\", \" \", text)\n",
    "    \n",
    "    # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
    "    text = re.sub(r\"\\@\\S+\", \" \", text)\n",
    "\n",
    "    # Replace everything not a letter with a space\n",
    "    text = re.sub(r\"[^a-z]+\", \" \", text)\n",
    "    \n",
    "    # Tokenize by splitting the string on whitespace into a list of words\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "    # Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(k, pos =\"v\") for k in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Class\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, lstm_size, output_size, lstm_layers=2, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        Parameters\n",
    "        ----------\n",
    "            vocab_size : The vocabulary size.\n",
    "            embed_size : The embedding layer size.\n",
    "            lstm_size : The LSTM layer size.\n",
    "            output_size : The output size.\n",
    "            lstm_layers : The number of LSTM layers.\n",
    "            dropout : The dropout probability.\n",
    "        \"\"\"\n",
    "    \n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # TODO Implement\n",
    "        \n",
    "        # Setup embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # Setup LSTM layer\n",
    "        # Reviewer advises batch_first=False as input is tuple of (seq_len,batch_size)\n",
    "        self.lstm = nn.LSTM(embed_size, lstm_size, lstm_layers, dropout = dropout, batch_first=False)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear layer\n",
    "        self.fc = nn.Linear(lstm_size, output_size)\n",
    "        \n",
    "        # sigmoid layer\n",
    "        self.sig = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" \n",
    "        Initializes hidden state\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size : The size of batches.\n",
    "        Returns\n",
    "        -------\n",
    "            hidden_state   \n",
    "        \"\"\"\n",
    "        # Initialize in CPU, then move to GPU for training\n",
    "            \n",
    "        # TODO Implement \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_().cuda(),\n",
    "                  weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_(),\n",
    "                      weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_())\n",
    "            \n",
    "        # Reviewer recommends following function to switch CPU to GPU for  training    \n",
    "        for each in hidden:\n",
    "            each.to(device)    \n",
    "        \n",
    "        return hidden\n",
    "\n",
    "\n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on nn_input.\n",
    "        Parameters\n",
    "        ----------\n",
    "            nn_input : The batch of input to the NN.\n",
    "            hidden_state : The LSTM hidden state.\n",
    "        Returns\n",
    "        -------\n",
    "            logps: log softmax output\n",
    "            hidden_state: The new hidden state.\n",
    "        \"\"\"\n",
    "        # TODO Implement \n",
    "        batch_size = nn_input.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        #nn_input = nn_input.long()\n",
    "        embeds = self.embedding(nn_input)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        #lstm_out = lstm_out.contiguous().view(-1, self.lstm_size)\n",
    "        # we are using a softmax layer we simplify implementation\n",
    "        # reviewer recommends following format\n",
    "        lstm_out = lstm_out[-1,:,:]\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # log sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        # reviewer recommends removing\n",
    "        # sig_out = sig_out.view(batch_size, -1)\n",
    "        # sig_out = sig_out[:,-5:] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(20939, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (sig): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Model\n",
    "model = TextClassifier(len(vocab)+1, 400, 256, 5, lstm_layers=2, dropout=0.2)\n",
    "\n",
    "pretrained_dict = torch.load(\"text_class_040819.pth\", map_location=lambda storage, loc: storage)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "#pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "model.load_state_dict(pretrained_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction Routine\n",
    "def predict(text, model, vocab):\n",
    "    \"\"\" \n",
    "    Make a prediction on a single sentence.\n",
    "    Parameters\n",
    "    ----------\n",
    "        text : The string to make a prediction on.\n",
    "        model : The model to use for making the prediction.\n",
    "        vocab : Dictionary for word to word ids. The key is the word and the value is the word id.\n",
    "    Returns\n",
    "    -------\n",
    "        pred : Prediction vector\n",
    "    \"\"\"    \n",
    "    \n",
    "    # TODO Implement\n",
    "    # Clean sentance and tokenize\n",
    "    tokens = preprocess(text)\n",
    "    \n",
    "    # Filter non-vocab words\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    \n",
    "    # Convert words to ids\n",
    "    token_ids = [vocab[w] for w in tokens]\n",
    "    \n",
    "    # Test length of token_ids is > zero\n",
    "    \n",
    "    if len(token_ids) > 0:\n",
    "        \n",
    "        # Adding a batch dimension\n",
    "        text_input = torch.LongTensor([0]*(12-len(tokens)) + token_ids)\n",
    "        \n",
    "        # Init Hidden\n",
    "        hidden = model.init_hidden(1)\n",
    "        \n",
    "        # Get the model info\n",
    "        logps, _ = model(text_input.unsqueeze(1), hidden)\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        pred = torch.exp(logps)\n",
    "        \n",
    "    else:\n",
    "        # Indeterminant\n",
    "        pred = torch.LongTensor([[0,0,0,0,0]])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Portland State University researchers have presented a blockchain protocol to fight counterfeit pharmaceuticals https://cointelegraph.com/news/us-researchers-develop-blockchain-protocol-to-fight-counterfeit-pharmaceuticals â€¦pic.twitter.com/AI4MGNWKnE'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a sample\n",
    "test_text = df_net_eng['tweet'][2]\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0221, 0.0752, 0.5878, 0.2892, 0.0258]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample results\n",
    "test_result = predict(test_text, model, vocab)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77491a00b0b4e29a4af39cd38cc8fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4573 entries, 0 to 4982\n",
      "Data columns (total 9 columns):\n",
      "date     4573 non-null object\n",
      "tweet    4573 non-null object\n",
      "id       4573 non-null object\n",
      "lang     4573 non-null object\n",
      "sen_0    4573 non-null float64\n",
      "sen_1    4573 non-null float64\n",
      "sen_2    4573 non-null float64\n",
      "sen_3    4573 non-null float64\n",
      "sen_4    4573 non-null float64\n",
      "dtypes: float64(5), object(4)\n",
      "memory usage: 517.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Iterate through all the tweets\n",
    "\n",
    "class_0 = []\n",
    "class_1 = []\n",
    "class_2 = []\n",
    "class_3 = []\n",
    "class_4 = []\n",
    "\n",
    "for i,tweet in tqdm_notebook(df_net_eng.iterrows()):\n",
    "    try:\n",
    "        #get tweet\n",
    "        tweet = df_net_eng['tweet'][i]\n",
    "\n",
    "        #predict\n",
    "        tweet_result = predict(tweet, model, vocab)\n",
    "\n",
    "        #convert tensor to np array\n",
    "        results_np = tweet_result.detach().numpy().tolist()\n",
    "        \n",
    "    except:\n",
    "        results_np = np.asarray([[0,0,0,0,0]]).tolist()\n",
    "\n",
    "    #append to dataframes\n",
    "    class_0.append(results_np[0][0])\n",
    "    class_1.append(results_np[0][1])\n",
    "    class_2.append(results_np[0][2])\n",
    "    class_3.append(results_np[0][3])\n",
    "    class_4.append(results_np[0][4])\n",
    "\n",
    "# write lists to dataframe\n",
    "df_net_eng['sen_0'] = class_0\n",
    "df_net_eng['sen_1'] = class_1\n",
    "df_net_eng['sen_2'] = class_2\n",
    "df_net_eng['sen_3'] = class_3\n",
    "df_net_eng['sen_4'] = class_4\n",
    "    \n",
    "df_net_eng.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>sen_0</th>\n",
       "      <th>sen_1</th>\n",
       "      <th>sen_2</th>\n",
       "      <th>sen_3</th>\n",
       "      <th>sen_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-15 15:58:36</td>\n",
       "      <td>ConsenSys is reportedly trying to attract outs...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "      <td>0.046712</td>\n",
       "      <td>0.061868</td>\n",
       "      <td>0.649117</td>\n",
       "      <td>0.189820</td>\n",
       "      <td>0.052482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-15 15:11:55</td>\n",
       "      <td>Don't miss the most memorable quotes from last...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "      <td>0.013756</td>\n",
       "      <td>0.147028</td>\n",
       "      <td>0.751772</td>\n",
       "      <td>0.079675</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-15 15:09:47</td>\n",
       "      <td>Portland State University researchers have pre...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>0.075189</td>\n",
       "      <td>0.587784</td>\n",
       "      <td>0.289166</td>\n",
       "      <td>0.025804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-15 14:01:08</td>\n",
       "      <td>Reuters: France to ask other EU states to adop...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>0.696270</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.020167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-15 13:11:07</td>\n",
       "      <td>Ethereum engineer Lukas Hohl has joined Swissc...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>en</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.670341</td>\n",
       "      <td>0.278097</td>\n",
       "      <td>0.016562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              tweet  \\\n",
       "0  2019-04-15 15:58:36  ConsenSys is reportedly trying to attract outs...   \n",
       "1  2019-04-15 15:11:55  Don't miss the most memorable quotes from last...   \n",
       "2  2019-04-15 15:09:47  Portland State University researchers have pre...   \n",
       "3  2019-04-15 14:01:08  Reuters: France to ask other EU states to adop...   \n",
       "4  2019-04-15 13:11:07  Ethereum engineer Lukas Hohl has joined Swissc...   \n",
       "\n",
       "              id lang     sen_0     sen_1     sen_2     sen_3     sen_4  \n",
       "0  Cointelegraph   en  0.046712  0.061868  0.649117  0.189820  0.052482  \n",
       "1  Cointelegraph   en  0.013756  0.147028  0.751772  0.079675  0.007769  \n",
       "2  Cointelegraph   en  0.022057  0.075189  0.587784  0.289166  0.025804  \n",
       "3  Cointelegraph   en  0.017009  0.063318  0.696270  0.203236  0.020167  \n",
       "4  Cointelegraph   en  0.006450  0.028550  0.670341  0.278097  0.016562  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view results\n",
    "df_net_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results to file for indexing to search engine\n",
    "df_net_eng.to_csv(\"df_tweet_net_eng_sen_r2.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
